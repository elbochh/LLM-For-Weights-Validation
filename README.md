# LLM-For-Weights-Validation

This repository implements the Large Language Model (LLM) layer of our hackathon project. It uses a Retrieval-Augmented Generation (RAG) pipeline to analyze management discussions (10-K/10-Q) and macroeconomic context, scoring long-short stock pairs across five fundamental dimensions (growth, cash generation, earnings outlook, downside risk, macro sensitivity).
The goal is to validate or swap portfolio weights generated by an external Reinforcement Learning model, ensuring the final portfolio reflects both quantitative and qualitative insights.


#  Overview

1. **Input:** RL-generated portfolio weights (one-month snapshot)
2. **Processing:**
   - Compute position changes (`calculate_position_changes.py`)
   - Link each stock to financial data and filings (`map_filings_to_transitions.py`)
   - Form long–short stock pairs (`pair_stocks.py`)
   - Summarize MD&A sections (`mgmt_summarizer.py`)
3. **LLM Scoring:**
   - Compare long vs. short company pairs using macro + textual context
   - Evaluate across 5 dimensions: growth, cash generation, earnings outlook, downside risk, and macro sensitivity
4. **Output:**
   - A scored file with “swap” decisions for potential portfolio adjustment


# Why This Matters

This pipeline represents a new generation of AI-driven portfolio intelligence, bridging the gap between data-driven models and qualitative financial reasoning.

Reinforcement Learning (RL) captures market dynamics and quantitative patterns, learning optimal portfolio weights from historical signals.

Large Language Models (LLMs) extract narrative insights from corporate filings and macroeconomic reports — signals that traditional quantitative models often overlook.

Together, they form a hybrid decision system that enhances portfolio robustness, transparency, and forward-looking adaptability — combining the precision of data with the intuition of context.
